{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall\n",
    "\n",
    "\n",
    "As part of supervised learning, prediction from a model can classified into two categories- Regression and Classification.\n",
    "\n",
    "In Supervised learning system learns from the data that has been provided as tranining and which contains both feature and dependendent variable.  \n",
    "\n",
    "For example- If we need to predict the Salary of an employee in an organization based on the Training data with some of the features like - Employee's experience, current Salary, Location etc. Organization will also have the data set of salary that they have provided to the hired employees. With this existing set of data System can predict the salary of an employee given the features like current salary, experience etc. This is considered as Regression where the predicted value is quantitive.\n",
    "\n",
    "Now lets consider the second category Classification, suppose you have to predict the the potenial customer for buying credit card, given salary, age, Gender, past purchasing history and some other feature. If we look carefully the regression module doesn't work here the predicted data is qualitative which means we have to predict whether customer will take credit card or not.(Yes/No). We can have some other qualitative classification like user ratings which can start from very bad to very good(1 to 5) which we can consider as multi-class classification.\n",
    "\n",
    "\n",
    "As we got some basic understanding now, before we discuss about Recall let's understand Confusion Matrix and it's use in classification.\n",
    "\n",
    "In the field of machine learning and specifically in case of statistical classification, confusion matrix is a specific table layout that allows visualization of the performance of an algorithm. Each row of this matrix represents the instances in a predicted class while each column represents the instances in an actual class (or vice versa). The name has been given to understand to see if the system is confusing two classes (i.e. commonly mislabeling one as another).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(url=\"https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see and example - If we see the below table for spam and non-spam filter of email in a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://4.bp.blogspot.com/-jNSCuV2OtOY/XMfoQka3qaI/AAAAAAAAEjY/TiFX8HALafAVzu_zp5njDqOoGCqzyVouwCLcBGAs/s1600/1_001%2Bnew.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://4.bp.blogspot.com/-jNSCuV2OtOY/XMfoQka3qaI/AAAAAAAAEjY/TiFX8HALafAVzu_zp5njDqOoGCqzyVouwCLcBGAs/s1600/1_001%2Bnew.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand the terms now - \n",
    "\n",
    "True Positive - As the term suggests it's the value of correctly predicted from the actual results.\n",
    "\n",
    "False Negative - These are the values in the table which predicted false but in actual it's true. For the above example model predicted the email as non-spam but in actual it's a spam. This is called Type 2 error.\n",
    "\n",
    "False Positive - These are the values in the table which predicted as true but in actual it's false. For the above example model predicted the email as spam but in it actual it's a non-spam. This is called Type 1 error.\n",
    "\n",
    "True Negative - These are the values in the table which predicted false and in actual it's false. For the above example model predicted the email as non-spam and it's actual it's non-spam."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So normally we check how accurately our model predicted the values, which is called Accuracy - \n",
    "\n",
    "Accuracy = $\\frac{TP+TN}{TP+FN+FP+TN}$\n",
    "\n",
    "But accuracy will not always be the reliable metric for the real performance of the model. Because it will lead to misleading results if the data is not balanced. For example of below unbalanced data\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Now for this we get an awesome accuracy of 93%. But is it a good model, the answer is no. Because the model mentioned 5 of the patients has no-cancer where they actually have and need to diagnosed.\n",
    "\n",
    "Or consider another example - Create a model to identify the terrorist board flights in airport for an year. So if we see the data from 500 milllion passengers only 11 of them are confirmed terrorists. But our prediction model mentioned all of them as not-terrorist. So we get an amazing accuracy of 99.99%. But will anyone buy this model? No way!!!\n",
    "\n",
    "Because of this unbalanced data we can't rely on accuracy for classification model. Here comes the two metrics which is important Recall and Precision.\n",
    "\n",
    "Recall/Sensitivity - Recall will be calculated as predicted postive value divided by the actual positive value. Eventually we want to get the answer of the question in what proportion did actual positives are identified correctly by the classifier.\n",
    "\n",
    "Formula - $\\frac{TP}{TP+FN}$\n",
    "\n",
    "We should always try to get high Recall value, because a model should always try to remove Type-2 error. \n",
    "\n",
    "Let's calculate the recall for above SPAM email example - \n",
    "\n",
    "R = $\\frac{45}{45+20}$ = 69.23% which actually means 69.23% correct emails are classified as Spam and excluded from non-spam emails.\n",
    "\n",
    "Along with the metrics Recall we should also calculate the value of Precision which is ratio of classified true postive example with total predicted true positive example.\n",
    "\n",
    "Formula - $\\frac{TP}{TP+FP}$\n",
    "\n",
    "From this two values we will calculate the F1-Score which is actually harmonic mean of Precision and Recall.\n",
    "\n",
    "Formula - 2*$\\frac{Precision*Recall}{Precision+Recall}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example in Python - \n",
    "\n",
    "We have a IRIS data set which contains 3 different variety of flower Sentosa, Versicolor and Virginica. With their sepal and petal length and width we will try to draw a confusion matrix and find Recall, Precision, Accuracy and F1 Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the confusion Matrix\n",
      " [[13  0  0]\n",
      " [ 0 10  6]\n",
      " [ 0  1  8]]\n",
      "Accuracy:0.8157894736842105\n",
      "Precision:[ 1.          0.90909091  0.57142857]\n",
      "Recall:[ 1.          0.625       0.88888889]\n",
      "F1-Score:[ 1.          0.74074074  0.69565217]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('C:/MongoDB/Python/iris.csv')\n",
    "X = dataset.iloc[:, 0:4].values\n",
    "y = dataset['variety'].values\n",
    "\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "y = labelencoder.fit_transform(y)\n",
    "\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Here is the confusion Matrix\\n',cm)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "ps = precision_score(y_test,y_pred, average=None)\n",
    "rc = recall_score(y_test,y_pred,average=None)\n",
    "f_sc = f1_score(y_test,y_pred,average=None)\n",
    "\n",
    "print(\"Accuracy:{}\\nPrecision:{}\\nRecall:{}\\nF1-Score:{}\".format(ac,ps,rc,f_sc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
